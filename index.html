<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Parallel Video Processing</title>
    <style>
      .video-container {
        display: flex;
        flex-wrap: wrap;
        gap: 20px;
        margin: 20px;
      }
      .video-item {
        width: 300px;
        display: flex;
        flex-direction: column;
        gap: 10px;
        position: relative;
      }
      .video-checkbox {
        position: absolute;
        top: 10px;
        right: 10px;
        width: 20px;
        height: 20px;
        z-index: 1;
      }
      video {
        width: 100%;
        height: 200px;
        border: 1px solid #ccc;
      }
      .controls {
        margin: 20px;
        padding: 20px;
        background: #f5f5f5;
        border-radius: 8px;
      }
      button {
        padding: 10px 20px;
        margin: 5px;
        cursor: pointer;
      }
      .progress-container {
        width: 100%;
        height: 20px;
        background-color: #f0f0f0;
        border-radius: 10px;
        overflow: hidden;
      }
      .progress-bar {
        height: 100%;
        background-color: #4caf50;
        width: 0%;
        transition: width 0.1s linear;
      }
      .processing-label {
        font-size: 14px;
        color: #666;
      }
      .thumbnail {
        width: 100%;
        height: 200px;
        object-fit: cover;
        border: 1px solid #ccc;
      }
      .waveform-container {
        width: 100%;
        height: 150px;
        margin-top: 10px;
        border: 1px solid #ccc;
        background: #f8f8f8;
      }
      .waveform-label {
        font-size: 12px;
        color: #666;
        margin-top: 5px;
      }
      .section {
        margin: 20px;
        padding: 20px;
        border: 1px solid #ddd;
        border-radius: 8px;
      }
      .section-title {
        font-size: 18px;
        font-weight: bold;
        margin-bottom: 15px;
      }
      .video-pair {
        display: flex;
        gap: 20px;
        margin-bottom: 20px;
      }
      .selected {
        border: 3px solid #4caf50;
      }
      .pair-card {
        width: 100%;
        max-width: 800px;
        margin: 20px auto;
        padding: 20px;
        border: 1px solid #ddd;
        border-radius: 8px;
        background: #fff;
      }
      .pair-videos {
        display: flex;
        gap: 20px;
        margin-bottom: 20px;
      }
      .pair-video {
        flex: 1;
        min-width: 0;
      }
      .alignment-results {
        margin-top: 20px;
        padding: 15px;
        background: #f8f8f8;
        border-radius: 8px;
      }
      .result-item {
        margin: 10px 0;
        padding: 10px;
        background: #fff;
        border-radius: 4px;
        border: 1px solid #eee;
      }
    </style>
  </head>
  <body>
    <div class="section">
      <div class="section-title">Upload Videos</div>
      <div class="controls">
        <input type="file" id="videoInput" multiple accept="video/*,.insv" />
      </div>
      <div class="video-container" id="videoContainer"></div>
    </div>

    <div class="section" id="pairSection" style="display: none">
      <div class="section-title">Pair Videos</div>
      <div class="controls">
        <button id="pairVideos">Pair Selected Videos</button>
      </div>
      <div class="pair-card" id="pairCard" style="display: none">
        <div class="pair-videos" id="videoPair"></div>
        <div class="alignment-results" id="alignmentResults"></div>
      </div>
    </div>

    <div class="section" id="processSection" style="display: none">
      <div class="section-title">Process Paired Videos</div>
      <div class="video-pair" id="videoPair"></div>
    </div>

    <script>
      const playbackRate = 6;
      const ctx = new AudioContext();
      const invertedPlaybackRate = 1 / playbackRate;
      const videoInput = document.getElementById('videoInput');
      const pairVideos = document.getElementById('pairVideos');
      const videoContainer = document.getElementById('videoContainer');
      const pairSection = document.getElementById('pairSection');
      const processSection = document.getElementById('processSection');

      let videoFiles = [];
      let selectedVideos = [];
      let processedVideos = [];
      let processedAudios = [];
      let pairCount = 0;

      videoInput.addEventListener('change', (e) => {
        videoFiles = Array.from(e.target.files);
        videoContainer.innerHTML = '';
        videoFiles.forEach((file, index) => {
          const videoItem = document.createElement('div');
          videoItem.className = 'video-item';
          videoItem.id = `video-item-${index}`;

          const checkbox = document.createElement('input');
          checkbox.type = 'checkbox';
          checkbox.className = 'video-checkbox';
          checkbox.id = `checkbox-${index}`;
          checkbox.onchange = () => toggleVideoSelection(index);

          const video = document.createElement('video');
          video.className = 'thumbnail';
          video.src = URL.createObjectURL(file);
          video.controls = true;

          const fileName = document.createElement('div');
          fileName.className = 'processing-label';
          fileName.textContent = file.name;

          videoItem.appendChild(checkbox);
          videoItem.appendChild(video);
          videoItem.appendChild(fileName);
          videoContainer.appendChild(videoItem);
        });
        pairSection.style.display = 'block';
      });

      function toggleVideoSelection(index) {
        const videoItem = document.getElementById(`video-item-${index}`);
        const checkbox = document.getElementById(`checkbox-${index}`);
        const isSelected = checkbox.checked;

        console.log(
          `Toggling selection for video ${index}, isSelected: ${isSelected}`
        );
        console.log(`Current selectedVideos:`, selectedVideos);

        if (isSelected) {
          videoItem.classList.add('selected');
          if (!selectedVideos.some((v) => v.index === index)) {
            selectedVideos.push({ index, file: videoFiles[index] });
          }
        } else {
          videoItem.classList.remove('selected');
          selectedVideos = selectedVideos.filter((v) => v.index !== index);
        }
        console.log(`Updated selectedVideos:`, selectedVideos);
      }

      pairVideos.addEventListener('click', async () => {
        console.log('Pair button clicked');
        console.log('Current selectedVideos:', selectedVideos);

        // Filter out any selected videos that are already hidden
        selectedVideos = selectedVideos.filter(({ index }) => {
          const videoItem = document.getElementById(`video-item-${index}`);
          return videoItem && videoItem.style.display !== 'none';
        });

        console.log('Filtered selectedVideos:', selectedVideos);

        if (selectedVideos.length !== 2) {
          alert('Please select exactly 2 videos to pair');
          return;
        }

        // Create a new pair card
        const newPairCard = document.createElement('div');
        newPairCard.className = 'pair-card';
        newPairCard.id = `pair-card-${pairCount}`;

        const pairVideosContainer = document.createElement('div');
        pairVideosContainer.className = 'pair-videos';
        pairVideosContainer.id = `video-pair-${pairCount}`;

        const alignmentResults = document.createElement('div');
        alignmentResults.className = 'alignment-results';
        alignmentResults.id = `alignment-results-${pairCount}`;

        newPairCard.appendChild(pairVideosContainer);
        newPairCard.appendChild(alignmentResults);
        document.getElementById('pairSection').appendChild(newPairCard);

        // Hide selected videos from upload section
        selectedVideos.forEach(({ index }) => {
          const videoItem = document.getElementById(`video-item-${index}`);
          videoItem.style.display = 'none';
          // Also uncheck the checkbox and remove selected class
          const checkbox = document.getElementById(`checkbox-${index}`);
          if (checkbox) {
            checkbox.checked = false;
          }
          videoItem.classList.remove('selected');
        });

        // Process the selected videos
        processedVideos = [];
        processedAudios = [];
        const processingPromises = selectedVideos.map(({ file }, index) =>
          processVideo(file, index, pairCount)
        );
        await Promise.all(processingPromises);
        const alignmentResult = await audioAlign(
          processedAudios[0],
          processedAudios[1]
        );

        // Update alignment results
        alignmentResults.innerHTML = `
          <div class="result-item">
            <strong>Audio Alignment Results:</strong><br>
            <span>Estimated offset: ${(
              alignmentResult.offset * playbackRate
            ).toFixed(3)} seconds</span><br>
            <span>Audio similarity confidence: ${alignmentResult.confidence.toFixed(
              1
            )}%</span>
          </div>
        `;

        // Clear selection for next pair
        selectedVideos = [];
        pairCount++;
      });

      async function processVideo(file, index, pairIndex) {
        return new Promise((resolve) => {
          const pairContainer = document.getElementById(
            `video-pair-${pairIndex}`
          );

          const videoContainer = document.createElement('div');
          videoContainer.className = 'pair-video';
          videoContainer.id = `processing-video-${pairIndex}-${index}`;

          // Create visible video element for the pair
          const displayVideo = document.createElement('video');
          displayVideo.className = 'thumbnail';
          displayVideo.src = URL.createObjectURL(file);
          displayVideo.controls = true;

          const progressContainer = document.createElement('div');
          progressContainer.className = 'progress-container';
          const progressBar = document.createElement('div');
          progressBar.className = 'progress-bar';
          progressContainer.appendChild(progressBar);

          const statusLabel = document.createElement('div');
          statusLabel.className = 'processing-label';
          statusLabel.textContent = 'Processing...';

          const audioPlayer = document.createElement('audio');
          audioPlayer.className = 'audio-player';
          audioPlayer.controls = true;
          audioPlayer.style.width = '100%';
          audioPlayer.style.marginTop = '10px';
          audioPlayer.style.display = 'none';

          videoContainer.appendChild(displayVideo);
          videoContainer.appendChild(progressContainer);
          videoContainer.appendChild(statusLabel);
          videoContainer.appendChild(audioPlayer);
          pairContainer.appendChild(videoContainer);

          // Create hidden video element for processing
          const processingVideo = document.createElement('video');
          processingVideo.src = URL.createObjectURL(file);
          processingVideo.style.display = 'none';
          document.body.appendChild(processingVideo);

          processingVideo.onloadedmetadata = () => {
            let mediaRecorder;
            let audioRecorder;
            let stream;

            stream = processingVideo.mozCaptureStream();

            // Try different codec configurations
            const codecConfigs = [
              { mimeType: 'video/webm' },
              { mimeType: 'video/webm;codecs=vp8' },
              { mimeType: 'video/webm;codecs=vp8,opus' },
              { mimeType: 'video/mp4' },
            ];

            const audioConfig = { mimeType: 'audio/webm' };

            let selectedConfig = null;
            for (const config of codecConfigs) {
              if (MediaRecorder.isTypeSupported(config.mimeType)) {
                selectedConfig = config;
                break;
              }
            }

            if (!selectedConfig) {
              statusLabel.textContent = 'Error: No supported codec found';
              resolve();
              return;
            }

            try {
              mediaRecorder = new MediaRecorder(stream, selectedConfig);

              // Create audio-only stream
              const audioStream = new MediaStream();
              stream.getAudioTracks().forEach((track) => {
                audioStream.addTrack(track);
              });

              audioRecorder = new MediaRecorder(audioStream, audioConfig);
            } catch (e) {
              statusLabel.textContent = 'Error: Failed to create MediaRecorder';
              console.error('MediaRecorder error:', e);
              resolve();
              return;
            }

            const videoChunks = [];
            const audioChunks = [];

            mediaRecorder.ondataavailable = (e) => {
              videoChunks.push(e.data);
            };

            audioRecorder.ondataavailable = (e) => {
              audioChunks.push(e.data);
            };

            mediaRecorder.onstop = () => {
              const videoBlob = new Blob(videoChunks, {
                type: selectedConfig.mimeType,
              });
              processedVideos.push(videoBlob);
              document.body.removeChild(processingVideo);
              statusLabel.textContent = 'Processing complete!';
            };

            audioRecorder.onstop = () => {
              const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
              processedAudios.push(audioBlob);
              audioPlayer.src = URL.createObjectURL(audioBlob);
              audioPlayer.playbackRate = invertedPlaybackRate;
              audioPlayer.style.display = 'block';
              resolve();
            };

            const duration = processingVideo.duration;
            const targetDuration = duration / playbackRate;
            let currentTime = 0;

            processingVideo.playbackRate = playbackRate;
            mediaRecorder.start();
            audioRecorder.start();
            processingVideo.play();

            const progressInterval = setInterval(() => {
              currentTime += 0.1;
              const progress = (currentTime / targetDuration) * 100;
              progressBar.style.width = `${Math.min(progress, 100)}%`;

              if (currentTime >= targetDuration) {
                clearInterval(progressInterval);
                mediaRecorder.stop();
                audioRecorder.stop();
              }
            }, 100);
          };
        });
      }

      async function audioAlign(audioBlob1, audioBlob2) {
        async function decode(file) {
          const buffer = await file.arrayBuffer();
          return ctx.decodeAudioData(buffer);
        }

        function calculateSimilarityConfidence(signal1, signal2) {
          // Only analyze first minute (adjusted by playback rate)
          const targetWindowSeconds = 60 / playbackRate;
          const maxSamples = Math.floor(targetWindowSeconds * ctx.sampleRate);

          // Take first minute of both signals
          const s1 = signal1.slice(0, maxSamples);
          const s2 = signal2.slice(0, maxSamples);

          // Calculate energy of both signals
          const energy1 = s1.reduce((sum, x) => sum + x * x, 0) / s1.length;
          const energy2 = s2.reduce((sum, x) => sum + x * x, 0) / s2.length;

          // Calculate energy ratio (how similar are the overall volumes)
          const energyRatio =
            Math.min(energy1, energy2) / Math.max(energy1, energy2);

          // Calculate cross-correlation at zero offset for overall similarity
          let correlation = 0;
          const minLength = Math.min(s1.length, s2.length);
          for (let i = 0; i < minLength; i += 64) {
            correlation += s1[i] * s2[i];
          }
          correlation = correlation / (minLength / 64);

          // Normalize correlation to 0-1 range
          const normalizedCorrelation = (correlation + 1) / 2;

          // Combine energy ratio and correlation for final confidence
          const confidence =
            (energyRatio * 0.4 + normalizedCorrelation * 0.6) * 100;

          return Math.min(100, Math.max(0, confidence));
        }

        function drawWaveform(canvas, signal, offset = 0, color = '#4caf50') {
          const ctx = canvas.getContext('2d');
          const width = canvas.width;
          const height = canvas.height;
          const centerY = height / 2;

          ctx.clearRect(0, 0, width, height);
          ctx.strokeStyle = color;
          ctx.lineWidth = 1;

          ctx.beginPath();
          for (let i = 0; i < width; i++) {
            const sampleIndex = Math.floor((i / width) * signal.length);
            const sample = signal[sampleIndex + offset] || 0;
            const y = centerY + sample * centerY;
            if (i === 0) {
              ctx.moveTo(i, y);
            } else {
              ctx.lineTo(i, y);
            }
          }
          ctx.stroke();
        }

        function findOffset(signal1, signal2) {
          console.log('Finding offset using cross-correlation...');
          console.log(`Signal 1 length: ${signal1.length} samples`);
          console.log(`Signal 2 length: ${signal2.length} samples`);

          // Normalize signals
          const normalizeSignal = (signal) => {
            let max = 0;
            for (let i = 0; i < signal.length; i++) {
              max = Math.max(max, Math.abs(signal[i]));
            }
            return signal.map((x) => x / max);
          };

          const norm1 = normalizeSignal(signal1);
          const norm2 = normalizeSignal(signal2);

          // Use the shorter signal as the reference
          const reference = norm2;
          const search = norm1;

          // Focus on first minute (adjusted by playback rate)
          const targetWindowSeconds = 60 / playbackRate;
          const maxOffset = Math.floor(targetWindowSeconds * ctx.sampleRate);
          console.log(
            `Searching in first ${targetWindowSeconds.toFixed(
              2
            )} seconds (${maxOffset} samples)`
          );

          let bestOffset = 0;
          let bestCorrelation = -Infinity;
          const correlations = [];

          // Perform cross-correlation with finer granularity
          for (let offset = 0; offset <= maxOffset; offset += 64) {
            // Reduced step size for more granularity
            let correlation = 0;
            let count = 0;

            // Compare overlapping parts
            for (let i = 0; i < reference.length; i += 64) {
              // Reduced step size for more granularity
              if (i + offset < search.length) {
                correlation += search[i + offset] * reference[i];
                count++;
              }
            }

            correlation = count > 0 ? correlation / count : 0;
            correlations.push({ offset, correlation });

            if (correlation > bestCorrelation) {
              bestCorrelation = correlation;
              bestOffset = offset;
              console.log(
                `New best offset: ${offset} samples (${(
                  offset / ctx.sampleRate
                ).toFixed(3)}s), correlation: ${correlation.toFixed(4)}`
              );
            }
          }

          // Log top 10 correlations
          correlations.sort((a, b) => b.correlation - a.correlation);
          console.log('\nTop 10 correlations:');
          correlations.slice(0, 10).forEach((c, i) => {
            console.log(
              `${i + 1}. Offset: ${c.offset} samples (${(
                c.offset / ctx.sampleRate
              ).toFixed(3)}s), Correlation: ${c.correlation.toFixed(4)}`
            );
          });

          return bestOffset;
        }
        const f1 = audioBlob1;
        const f2 = audioBlob2;
        console.log('f1 and f2:');
        console.log(f1, f2);
        if (!f1 || !f2) return alert('Select both files!');

        console.log('Starting audio comparison...');
        console.log(`File 1: ${f1.name}, size: ${f1.size} bytes`);
        console.log(`File 2: ${f2.name}, size: ${f2.size} bytes`);

        const [b1, b2] = await Promise.all([decode(f1), decode(f2)]);
        currentBuffers = [b1, b2];
        const hop = 1024; // Using larger hop for raw signal
        const fs = ctx.sampleRate;

        console.log(`Audio context sample rate: ${fs} Hz`);
        console.log(`File 1 duration: ${b1.duration.toFixed(3)} seconds`);
        console.log(`File 2 duration: ${b2.duration.toFixed(3)} seconds`);

        // Get the raw audio data
        const signal1 = b1.getChannelData(0);
        const signal2 = b2.getChannelData(0);

        // Find the offset using cross-correlation
        const offsetSamples = findOffset(signal1, signal2);
        const offsetSeconds = offsetSamples / fs;

        // Calculate similarity confidence
        const confidence = calculateSimilarityConfidence(signal1, signal2);

        // Draw waveforms
        // const videoItems = document.querySelectorAll('.video-item');
        // const canvas1 = videoItems[0].querySelector('canvas');
        // const canvas2 = videoItems[1].querySelector('canvas');

        // drawWaveform(canvas1, signal1, 0, '#4caf50');
        // drawWaveform(canvas2, signal2, offsetSamples, '#2196f3');
        return { offset: offsetSeconds, confidence };
      }

      async function getVideoDuration(file) {
        return new Promise((resolve) => {
          const video = document.createElement('video');
          video.preload = 'metadata';
          video.onloadedmetadata = () => {
            resolve(video.duration);
          };
          video.src = URL.createObjectURL(file);
        });
      }
    </script>
  </body>
</html>
